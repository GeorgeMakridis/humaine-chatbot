# ğŸš€ Enhanced AI Profiler - HumAIne-Chatbot

## Overview

The Enhanced AI Profiler is a comprehensive user profiling system that provides real-time personalization through advanced language analysis, cross-session learning, and persistent profile storage. This system transforms the HumAIne-chatbot from a basic chatbot into an intelligent, adaptive AI assistant.

## âœ¨ Key Features

### **1. Profile Persistence**
- **Automatic Saving**: User profiles are automatically saved to disk
- **Cross-Restart Persistence**: Profiles survive server restarts
- **JSON Storage**: Human-readable profile files in `data/profiles/`
- **Backup & Recovery**: Built-in profile management and recovery

### **2. Enhanced Language Analysis**
- **Complexity Assessment**: Flesch Reading Ease, Gunning Fog, SMOG Index
- **Sentiment Analysis**: Emotional tone detection and enthusiasm measurement
- **Grammar Evaluation**: Writing quality and structure analysis
- **Vocabulary Richness**: Type-token ratio, hapax legomena analysis
- **Overall Language Score**: Composite quality assessment

### **3. Cross-Session Learning**
- **Pattern Recognition**: Identifies user behavior patterns across sessions
- **Engagement Tracking**: Monitors user engagement trends over time
- **Communication Analysis**: Analyzes consistency in communication preferences
- **Feedback Learning**: Tracks feedback patterns and improvement trends
- **Insight Generation**: Provides actionable insights and recommendations

### **4. Advanced Personalization**
- **Dynamic Adaptation**: Real-time profile updates based on user behavior
- **Response Optimization**: Tailors responses to user expertise and preferences
- **Style Matching**: Adapts communication style to user preferences
- **Complexity Adjustment**: Automatically adjusts language complexity
- **Detail Level Control**: Provides appropriate level of detail

## ğŸ—ï¸ Architecture

### **Core Components**

```
Enhanced AI Profiler
â”œâ”€â”€ Profile Persistence
â”‚   â”œâ”€â”€ ProfilePersistence
â”‚   â”œâ”€â”€ JSON Storage
â”‚   â””â”€â”€ Backup/Recovery
â”œâ”€â”€ Language Analysis
â”‚   â”œâ”€â”€ EnhancedLanguageAnalyzer
â”‚   â”œâ”€â”€ Complexity Metrics
â”‚   â”œâ”€â”€ Sentiment Analysis
â”‚   â””â”€â”€ Grammar Evaluation
â”œâ”€â”€ Cross-Session Learning
â”‚   â”œâ”€â”€ CrossSessionLearner
â”‚   â”œâ”€â”€ Pattern Recognition
â”‚   â”œâ”€â”€ Trend Analysis
â”‚   â””â”€â”€ Insight Generation
â””â”€â”€ User Profiler
    â”œâ”€â”€ Real-time Updates
    â”œâ”€â”€ Personalization
    â””â”€â”€ Integration Layer
```

### **Data Flow**

```
User Input â†’ Language Analysis â†’ Profile Update â†’ Cross-Session Learning â†’ Personalization â†’ Response
     â†“              â†“              â†“              â†“              â†“
  Metrics      Complexity      Persistence    Patterns      Tailored
Collection    Assessment      Storage        Recognition   Responses
```

## ğŸš€ Quick Start

### **1. Start the Backend**
```bash
# Start the enhanced backend
python main.py

# Or with Docker
docker-compose up -d
```

### **2. Run the Demo**
```bash
# Run the comprehensive demo
python demo_enhanced_profiler.py
```

### **3. Test Individual Features**
```bash
# Test OpenAI integration
python test_openai_integration.py

# Test profile endpoints
curl -H "Authorization: Bearer test-api-key-123" \
     http://localhost:8000/health
```

## ğŸ“Š API Endpoints

### **Core Chat Endpoints**
- `POST /interact` - Process user messages with enhanced profiling
- `POST /feedback` - Handle user feedback and update profiles
- `POST /session` - Manage session lifecycle and analytics

### **Enhanced Profiling Endpoints**
- `GET /profile/{user_id}` - Get comprehensive user profile and insights
- `GET /profiles/stats` - Get statistics about all user profiles
- `GET /profiles/insights/{user_id}` - Get detailed user insights
- `POST /profiles/save` - Save all profiles to disk
- `GET /health` - Health check with OpenAI and profiling status

## ğŸ§ª Demo Scenarios

### **Scenario 1: Expert User**
- **Input**: Complex, technical questions with sophisticated language
- **Analysis**: High complexity, advanced vocabulary, formal style
- **Profile Update**: Expertise level â†’ Expert, Detail â†’ Detailed
- **Response**: Technical, comprehensive, advanced explanations

### **Scenario 2: Beginner User**
- **Input**: Simple questions with basic language
- **Analysis**: Low complexity, basic vocabulary, casual style
- **Profile Update**: Expertise level â†’ Beginner, Detail â†’ Concise
- **Response**: Simple, clear, basic explanations

### **Scenario 3: Casual User**
- **Input**: Mixed complexity with conversational tone
- **Analysis**: Medium complexity, varied vocabulary, friendly style
- **Profile Update**: Expertise level â†’ Intermediate, Style â†’ Conversational
- **Response**: Balanced, friendly, moderate detail

## ğŸ” Profile Analysis

### **Language Complexity Metrics**
```json
{
  "complexity_analysis": {
    "flesch_reading_ease": 65.2,
    "flesch_kincaid_grade": 8.1,
    "gunning_fog": 12.3,
    "complexity_level": "standard"
  }
}
```

### **Sentiment Analysis**
```json
{
  "sentiment_analysis": {
    "sentiment_score": 0.7,
    "sentiment_label": "positive",
    "enthusiasm_level": "high",
    "exclamation_count": 2
  }
}
```

### **Cross-Session Insights**
```json
{
  "patterns": {
    "timing": {
      "avg_session_duration": 180000,
      "session_frequency_per_day": 1.2,
      "time_preferences": {"morning": 3, "afternoon": 2}
    },
    "engagement": {
      "engagement_trend": "increasing",
      "engagement_level": "medium"
    }
  },
  "insights": [
    "User engagement is improving over time",
    "User prefers morning sessions"
  ]
}
```

## ğŸ› ï¸ Configuration

### **Environment Variables**
```bash
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4

# Profiling Configuration
PROFILES_DIR=data/profiles
LANGUAGE_ANALYSIS_ENABLED=true
CROSS_SESSION_LEARNING_ENABLED=true

# Storage Configuration
PROFILE_PERSISTENCE_ENABLED=true
PROFILE_BACKUP_INTERVAL=3600
```

### **Profile Storage Structure**
```
data/
â”œâ”€â”€ profiles/
â”‚   â”œâ”€â”€ user_123.json
â”‚   â”œâ”€â”€ user_456.json
â”‚   â””â”€â”€ user_789.json
â”œâ”€â”€ virtual_personas/
â””â”€â”€ user_sessions/
```

## ğŸ“ˆ Performance Metrics

### **Analysis Speed**
- **Language Analysis**: ~50-100ms per message
- **Profile Update**: ~10-20ms per update
- **Cross-Session Learning**: ~100-200ms per session
- **Profile Persistence**: ~20-50ms per save

### **Storage Efficiency**
- **Profile Size**: ~2-5KB per user profile
- **Memory Usage**: ~1-2MB per 1000 profiles
- **Disk I/O**: Minimal, only on profile changes

## ğŸ”§ Troubleshooting

### **Common Issues**

#### **1. Profile Loading Errors**
```bash
# Check profile directory permissions
ls -la data/profiles/

# Verify JSON file integrity
python -m json.tool data/profiles/user_123.json
```

#### **2. Language Analysis Failures**
```bash
# Check NLTK data
python -c "import nltk; nltk.download('punkt')"

# Verify textstat installation
python -c "import textstat; print('textstat OK')"
```

#### **3. Performance Issues**
```bash
# Monitor profile count
curl -H "Authorization: Bearer test-api-key-123" \
     http://localhost:8000/profiles/stats

# Check memory usage
docker stats humaine-chatbot-backend
```

### **Debug Commands**
```bash
# Test individual components
python -c "from src.core.user_profiler import UserProfiler; print('Profiler OK')"
python -c "from src.utils.enhanced_language_analyzer import EnhancedLanguageAnalyzer; print('Analyzer OK')"

# Check profile persistence
python -c "from src.core.profile_persistence import ProfilePersistence; print('Persistence OK')"
```

## ğŸš€ Advanced Usage

### **Custom Language Analysis**
```python
from src.utils.enhanced_language_analyzer import EnhancedLanguageAnalyzer

analyzer = EnhancedLanguageAnalyzer()
analysis = analyzer.analyze_text("Your text here")
print(analysis['overall_score'])
```

### **Cross-Session Pattern Analysis**
```python
from src.core.cross_session_learner import CrossSessionLearner

learner = CrossSessionLearner()
patterns = learner.analyze_user_patterns(user_id, profiles)
print(patterns['insights'])
```

### **Profile Management**
```python
from src.core.user_profiler import UserProfiler

profiler = UserProfiler()
profiler.save_all_profiles()
stats = profiler.get_profile_stats()
```

## ğŸ“š API Documentation

### **Interactive API Docs**
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **OpenAPI Schema**: http://localhost:8000/openapi.json

### **Example Requests**
```bash
# Get user profile
curl -H "Authorization: Bearer test-api-key-123" \
     http://localhost:8000/profile/user_123

# Get profile statistics
curl -H "Authorization: Bearer test-api-key-123" \
     http://localhost:8000/profiles/stats

# Save all profiles
curl -X POST -H "Authorization: Bearer test-api-key-123" \
     http://localhost:8000/profiles/save
```

## ğŸ¯ What's Next

### **Immediate Enhancements**
1. **Database Integration**: Replace JSON storage with PostgreSQL
2. **Real-time Analytics**: WebSocket-based live profile updates
3. **A/B Testing**: Profile-based response optimization testing
4. **Export/Import**: Profile migration and backup tools

### **Advanced Features**
1. **Multi-language Support**: Extend language analysis to other languages
2. **Behavioral Modeling**: Advanced ML models for user behavior prediction
3. **Privacy Controls**: GDPR-compliant profile management
4. **API Rate Limiting**: Profile-based rate limiting and quotas

## ğŸ¤ Contributing

### **Development Setup**
```bash
# Clone and setup
git clone <repository>
cd humaine-chatbot
pip install -r requirements.txt

# Run tests
python -m pytest tests/

# Format code
black src/
ruff check src/
```

### **Testing**
```bash
# Run enhanced profiler demo
python demo_enhanced_profiler.py

# Run individual tests
python test_openai_integration.py
python -m pytest tests/test_profiler.py
```

## ğŸ“„ License

This project is funded by the European Union's Project HumAIne under grant agreement no 101120218.

---

**Status**: âœ… **Enhanced AI Profiler Complete**  
**Features**: ğŸš€ **Profile Persistence, Language Analysis, Cross-Session Learning**  
**Ready for**: Production Use, Research, Development, Demo
